{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StyleGAN2 with adaptive discriminator augmentation (ADA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51068,
     "status": "ok",
     "timestamp": 1627827882196,
     "user": {
      "displayName": "Code With Aarohi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDykKNncQS1xHrEv4HD6AW1rHDwSSAtc6R39fACA=s64",
      "userId": "13171438620520647509"
     },
     "user_tz": -330
    },
    "id": "XprG9itJ2uBD",
    "outputId": "2429d705-2acd-4c8d-e174-c590927ef1c4"
   },
   "outputs": [],
   "source": [
    "# Follow NVDIEA System requirement from https://github.com/NVlabs/stylegan2-ada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1627827882196,
     "user": {
      "displayName": "Code With Aarohi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDykKNncQS1xHrEv4HD6AW1rHDwSSAtc6R39fACA=s64",
      "userId": "13171438620520647509"
     },
     "user_tz": -330
    },
    "id": "5ZHjlcQP2xQu"
   },
   "outputs": [],
   "source": [
    "# Clone the StyleGAN2-ADA repository and go inside the directory\n",
    "\n",
    "!git clone https://github.com/NVlabs/stylegan2-ada.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1627827882196,
     "user": {
      "displayName": "Code With Aarohi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDykKNncQS1xHrEv4HD6AW1rHDwSSAtc6R39fACA=s64",
      "userId": "13171438620520647509"
     },
     "user_tz": -330
    },
    "id": "G2fnTPv826h3",
    "outputId": "5bb4795d-d497-4d03-8f3c-5f9c39a4d3d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\n"
     ]
    }
   ],
   "source": [
    "cd stylegan2-ada/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1627827882197,
     "user": {
      "displayName": "Code With Aarohi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDykKNncQS1xHrEv4HD6AW1rHDwSSAtc6R39fACA=s64",
      "userId": "13171438620520647509"
     },
     "user_tz": -330
    },
    "id": "TwUvdDCK5LEN"
   },
   "source": [
    "1- Download images from internet and put them in one folder.\n",
    "\n",
    "2- All the images are square and the same size.\n",
    "\n",
    "3- Code needs the dataset to be in .tfrecords format. We first need to convert our dataset to this format. \n",
    "   StyleGAN2-ADA has made a script that makes this conversion easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45062,
     "status": "ok",
     "timestamp": 1627827952912,
     "user": {
      "displayName": "Code With Aarohi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDykKNncQS1xHrEv4HD6AW1rHDwSSAtc6R39fACA=s64",
      "userId": "13171438620520647509"
     },
     "user_tz": -330
    },
    "id": "sF-qfAkJ-Xwc",
    "outputId": "c4d2761f-1453-4284-a91e-48fc0059d58d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "path = 'custom_dataset/cars_dataset_stylegan2/'\n",
    "\n",
    "\n",
    "im_size = 1024   # Input image resolution must be a power-of-two otherwise you will get error. \n",
    "                 #Pixel resolutions that are powers of 2 (512 x 512, 1024 x 1024, 2048 x 2048, etc).\n",
    "\n",
    "images = []\n",
    "\n",
    "for file in os.listdir(path):\n",
    "        img = cv2.imread(path + '/' + file)  # reading that image as array\n",
    "        img = cv2.resize(img, (im_size, im_size))\n",
    "        print(img.shape)\n",
    "        images.append(img)\n",
    "        # Save the image in Output Folder\n",
    "        cv2.imwrite('custom_dataset/resized_dataset/' + str(file) + '_resized.jpg', img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting images into .tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31072,
     "status": "ok",
     "timestamp": 1627827983975,
     "user": {
      "displayName": "Code With Aarohi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDykKNncQS1xHrEv4HD6AW1rHDwSSAtc6R39fACA=s64",
      "userId": "13171438620520647509"
     },
     "user_tz": -330
    },
    "id": "nAloDQez5vu3",
    "outputId": "a8aeae32-1a0e-44d2-a743-3a779c180e5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "256x256/Conv1_down   295168    (?, 256, 128, 128)  (3, 3, 128, 256)\n",
      "256x256/Skip         32768     (?, 256, 128, 128)  (1, 1, 128, 256)\n",
      "128x128/Conv0        590080    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
      "128x128/Conv1_down   1180160   (?, 512, 64, 64)    (3, 3, 256, 512)\n",
      "128x128/Skip         131072    (?, 512, 64, 64)    (1, 1, 256, 512)\n",
      "64x64/Conv0          2359808   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
      "64x64/Conv1_down     2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "64x64/Skip           262144    (?, 512, 32, 32)    (1, 1, 512, 512)\n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "Output               513       (?, 1)              (512, 1)        \n",
      "---                  ---       ---                 ---             \n",
      "Total                28982849                                      \n",
      "\n",
      "Exporting sample images...\n",
      "Replicating networks across 1 GPUs...\n",
      "Initializing augmentations...\n",
      "Setting up optimizers...\n",
      "Constructing training graph...\n",
      "Finalizing training ops...\n",
      "Initializing metrics...\n",
      "Training for 25000 kimg...\n",
      "\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.62.0-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python36\\site-packages (from tqdm) (0.4.3)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.62.0\n",
      "Loading images from \"custom_dataset/resized_dataset\"\n",
      "Creating dataset \"custom_dataset/tfrecords_dataset/\"\n",
      "0 / 55\n",
      "10 / 55\n",
      "20 / 55\n",
      "30 / 55\n",
      "40 / 55"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 / 55\n",
      "Flushing data...                        \n",
      "                                        \n",
      "Added 55 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Below command will create a multi-resolution .tfrecord file in /custom_dataset/tfrecords_dataset/ folder.\n",
    "!pip install tqdm\n",
    "\n",
    "\n",
    "!python dataset_tool.py create_from_images custom_dataset/tfrecords_dataset/ custom_dataset/resized_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 184923,
     "status": "ok",
     "timestamp": 1627828168896,
     "user": {
      "displayName": "Code With Aarohi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDykKNncQS1xHrEv4HD6AW1rHDwSSAtc6R39fACA=s64",
      "userId": "13171438620520647509"
     },
     "user_tz": -330
    },
    "id": "rSPgyXVP-S-T",
    "outputId": "bf11b2e0-87e3-4df8-8c58-80a39ef183ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 16384,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 16384,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 6.5536\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-02 17:38:26.264164: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-02 17:38:26.264206: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-02 17:38:28.666230: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-02 17:38:28.666272: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-02 17:38:29.233774: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-02 17:38:29.233802: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-02 17:39:36.880269: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 257.00MiB (rounded to 269485056).  Current allocation summary follows.\n",
      "2021-08-02 17:39:36.884510: W tensorflow/core/common_runtime/bfc_allocator.cc:319] ****************************************************************************************************\n",
      "2021-08-02 17:39:36.884530: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at conv_grad_input_ops.cc:903 : Resource exhausted: OOM when allocating tensor with shape[8,64,513,513] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1356, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1341, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1429, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[8,64,513,513] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node Train_gpu0/G/G_synthesis/512x512/Conv0_up/conv2d_transpose}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 561, in <module>\n",
      "    main()\n",
      "  File \"train.py\", line 553, in main\n",
      "    run_training(**vars(args))\n",
      "  File \"train.py\", line 451, in run_training\n",
      "    training_loop.training_loop(**training_options)\n",
      "  File \"D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\training\\training_loop.py\", line 247, in training_loop\n",
      "    tflib.run([G_train_op, data_fetch_op])\n",
      "  File \"D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\dnnlib\\tflib\\tfutil.py\", line 33, in run\n",
      "    return tf.get_default_session().run(*args, **kwargs)\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 950, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1173, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1350, in _do_run\n",
      "    run_metadata)\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1370, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[8,64,513,513] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[node Train_gpu0/G/G_synthesis/512x512/Conv0_up/conv2d_transpose (defined at D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\dnnlib\\tflib\\ops\\upfirdn_2d.py:306) ]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\n",
      "\n",
      "Errors may have originated from an input operation.\n",
      "Input Source operations connected to node Train_gpu0/G/G_synthesis/512x512/Conv0_up/conv2d_transpose:\n",
      " Train_gpu0/G/G_synthesis/512x512/Conv0_up/mul_7 (defined at D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\training\\networks.py:120)\t\n",
      " Train_gpu0/G/G_synthesis/512x512/Conv0_up/Reshape_1 (defined at D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\dnnlib\\tflib\\ops\\upfirdn_2d.py:303)\n",
      "\n",
      "Original stack trace for 'Train_gpu0/G/G_synthesis/512x512/Conv0_up/conv2d_transpose':\n",
      "  File \"train.py\", line 561, in <module>\n",
      "    main()"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1,\n",
      "      \"imgfilter\": 1,\n",
      "      \"noise\": 1,\n",
      "      \"cutout\": 1\n",
      "    }\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 10,\n",
      "  \"network_snapshot_ticks\": 10,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"custom_dataset/tfrecords_dataset\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 512,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"custom_dataset/tfrecords_dataset\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 512,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 25000,\n",
      "  \"minibatch_size\": 8,\n",
      "  \"minibatch_gpu\": 8,\n",
      "  \"G_smoothing_kimg\": 2.5,\n",
      "  \"G_smoothing_rampup\": 0.05,\n",
      "  \"run_dir\": \"./results\\\\00016-tfrecords_dataset-res512-auto1-bgcfnc\"\n",
      "}\n",
      "\n",
      "Output directory:  ./results\\00016-tfrecords_dataset-res512-auto1-bgcfnc\n",
      "Training data:     custom_dataset/tfrecords_dataset\n",
      "Training length:   25000 kimg\n",
      "Resolution:        512\n",
      "Number of GPUs:    1\n",
      "\n",
      "Creating output directory...\n",
      "Loading training set...\n",
      "Image shape: [3, 512, 512]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "G_mapping/Normalize           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 16, 512)        -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "Truncation/Lerp               -         (?, 16, 512)        -               \n",
      "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
      "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
      "G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
      "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)  \n",
      "G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n",
      "G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
      "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)  \n",
      "G_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\n",
      "G_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
      "G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n",
      "G_synthesis/256x256/ToRGB     66051     (?, 3, 256, 256)    (1, 1, 128, 3)  \n",
      "G_synthesis/512x512/Conv0_up  139457    (?, 64, 512, 512)   (3, 3, 128, 64) \n",
      "G_synthesis/512x512/Conv1     69761     (?, 64, 512, 512)   (3, 3, 64, 64)  \n",
      "G_synthesis/512x512/Upsample  -         (?, 3, 512, 512)    -               \n",
      "G_synthesis/512x512/ToRGB     33027     (?, 3, 512, 512)    (1, 1, 64, 3)   \n",
      "---                           ---       ---                 ---             \n",
      "Total                         28700647                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 512, 512)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "512x512/FromRGB      256       (?, 64, 512, 512)   (1, 1, 3, 64)   \n",
      "512x512/Conv0        36928     (?, 64, 512, 512)   (3, 3, 64, 64)  \n",
      "512x512/Conv1_down   73856     (?, 128, 256, 256)  (3, 3, 64, 128) \n",
      "512x512/Skip         8192      (?, 128, 256, 256)  (1, 1, 64, 128) \n",
      "256x256/Conv0        147584    (?, 128, 256, 256)  (3, 3, 128, 128)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  File \"train.py\", line 553, in main\n",
      "    run_training(**vars(args))\n",
      "  File \"train.py\", line 451, in run_training\n",
      "    training_loop.training_loop(**training_options)\n",
      "  File \"D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\training\\training_loop.py\", line 187, in training_loop\n",
      "    terms = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, aug=aug, fake_labels=fake_labels, real_images=real_images_var, real_labels=real_labels_var, **loss_args)\n",
      "  File \"D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\dnnlib\\util.py\", line 281, in call_func_by_name\n",
      "    return func_obj(*args, **kwargs)\n",
      "  File \"D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\training\\loss.py\", line 95, in stylegan2\n",
      "    G_fake = eval_G(G, fake_latents, fake_labels, return_dlatents=True)\n",
      "  File \"D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\training\\loss.py\", line 47, in eval_G\n",
      "    r.images = G.get_output_for(latents, labels, **r.args)\n",
      "  File \"D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\dnnlib\\tflib\\network.py\", line 369, in get_output_for\n",
      "    out_expr = self._build_func(*final_inputs, **build_kwargs)\n",
      "  File \"D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\training\\networks.py\", line 274, in G_main\n",
      "    images_out = components.synthesis.get_output_for(dlatents, is_training=is_training, force_clean_graph=is_template_graph, **kwargs)\n",
      "  File \"D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\dnnlib\\tflib\\network.py\", line 369, in get_output_for\n",
      "    out_expr = self._build_func(*final_inputs, **build_kwargs)\n",
      "  File \"D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\training\\networks.py\", line 446, in G_synthesis\n",
      "    x = block(x, res)\n",
      "  File \"D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\training\\networks.py\", line 407, in block\n",
      "    x = layer(x, layer_idx=res*2-5, fmaps=nf(res-1), kernel=3, up=True)\n",
      "  File \"D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\training\\networks.py\", line 392, in layer\n",
      "    x = modulated_conv2d_layer(x, dlatents_in[:, layer_idx], fmaps=fmaps, kernel=kernel, up=up, resample_kernel=resample_kernel, fused_modconv=fused_modconv)\n",
      "  File \"D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\training\\networks.py\", line 123, in modulated_conv2d_layer\n",
      "    x = conv2d(x, tf.cast(w, x.dtype), up=up, down=down, resample_kernel=resample_kernel)\n",
      "  File \"D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\training\\networks.py\", line 73, in conv2d\n",
      "    x = upsample_conv_2d(x, w, data_format='NCHW', k=resample_kernel, padding=padding)\n",
      "  File \"D:\\styleGAN_with_anaconda\\stylegan2_ADA\\stylegan2-ada\\dnnlib\\tflib\\ops\\upfirdn_2d.py\", line 306, in upsample_conv_2d\n",
      "    x = tf.nn.conv2d_transpose(x, w, output_shape=output_shape, strides=stride, padding='VALID', data_format=data_format)\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2147, in conv2d_transpose\n",
      "    name=name)\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2218, in conv2d_transpose_v2\n",
      "    name=name)\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1529, in conv2d_backprop_input\n",
      "    name=name)\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training StyleGAN2-ADA\n",
    "\n",
    "# snap is how often you want to save the model and sample results\n",
    "# res is what image resolution you want to train on\n",
    "# augpipe is augmentation pipes, such as 'blit', 'geom', 'color', 'filter', 'noise', 'cutout' or combination of these\n",
    "\n",
    "\n",
    "\n",
    "!python train.py --outdir ./results --snap=10 --data=custom_dataset/tfrecords_dataset --augpipe=bgcfnc --res=512 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1627828191883,
     "user": {
      "displayName": "Code With Aarohi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDykKNncQS1xHrEv4HD6AW1rHDwSSAtc6R39fACA=s64",
      "userId": "13171438620520647509"
     },
     "user_tz": -330
    },
    "id": "frkh4DR2Fvxl"
   },
   "outputs": [],
   "source": [
    "# There are many other arguments that you can modify, feel free to check the train.py code to learn more about the arguments.\n",
    "# Once you run the command, it will start training and periodically save the result and the model file (.pkl) based on the snap arguments\n",
    "# that you provided (In this case, every 10kimg). Once you think that the result is good enough or the FID starts to plateau, you can stop training and use the last saved .pkl file.\n",
    "\n",
    "# Once you have the model file you can generate images using this command.\n",
    "\n",
    "#!python generate.py --outdir=out --trunc=0.5 --seeds=600-605 --network={path_to_pkl_model_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Vybo5B_Hv5y"
   },
   "source": [
    "## As We don't have that much memory which can train styleGAN2. So we will download any pretrained model on styleGAN2 and see how to generate images from that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/cifar10.pkl\"...\n",
      "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n",
      "Generating image for seed 0 (0/11) ...\n",
      "Generating image for seed 1 (1/11) ...\n",
      "Generating image for seed 2 (2/11) ...\n",
      "Generating image for seed 3 (3/11) ...\n",
      "Generating image for seed 4 (4/11) ...\n",
      "Generating image for seed 5 (5/11) ...\n",
      "Generating image for seed 6 (6/11) ...\n",
      "Generating image for seed 7 (7/11) ...\n",
      "Generating image for seed 8 (8/11) ...\n",
      "Generating image for seed 9 (9/11) ...\n",
      "Generating image for seed 10 (10/11) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-02 16:52:11.743285: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-02 16:52:11.743326: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Generate class conditional CIFAR-10 images (Fig.17 left, Car)\n",
    "#!python generate.py --outdir=out --trunc=1 --seeds=0-35 --class=1 --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/cifar10.pkl\n",
    "\n",
    "!python generate.py --outdir=out1 --trunc=1 --seeds=0-10 --class=1 --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/cifar10.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOS9kZVLODeALxaK26do9k6",
   "collapsed_sections": [],
   "name": "stylegan2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
